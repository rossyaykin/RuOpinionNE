{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "057355f9",
   "metadata": {},
   "source": [
    "В этом ноутбуке кортежи мнений предсказываются с помощью модели Mistral Large 2 (mistral-large-latest).\n",
    "\n",
    "Для использования необходим Mistral API key, который можно получить бесплатно."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d150cd1",
   "metadata": {},
   "source": [
    "### Проверка ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "48af8e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import ast\n",
    "import json\n",
    "import os\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import random\n",
    "from random import choices\n",
    "import time\n",
    "\n",
    "api_key = \"YOUR_API_KEY\"\n",
    "model = \"mistral-large-latest\"\n",
    "url = \"https://api.mistral.ai/v1/chat/completions\"\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {api_key}\"\n",
    "}\n",
    "SEED = 42\n",
    "\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f2183e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Date': 'Wed, 27 Nov 2024 02:11:13 GMT', 'Content-Type': 'application/json; charset=utf-8', 'Content-Length': '96', 'Connection': 'keep-alive', 'www-authenticate': 'Key', 'access-control-allow-origin': '*', 'x-kong-response-latency': '1', 'x-kong-request-id': '83d989298e086e0226bcaf4e6adcf534', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '8e8e9616af716f72-CDG', 'alt-svc': 'h3=\":443\"; ma=86400'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = requests.get(url)\n",
    "response.headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cb7750f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: тебя создали французы?\n",
      "Ответ: Нет, меня создала Mistral AI, передовая французская компания в области искусственного интеллекта.\n"
     ]
    }
   ],
   "source": [
    "class MistralModel():\n",
    "    def __init__(self, model, temp = 0.2, top_p = 0.9, max_tokens = 256, seed = 42):\n",
    "        self.model = model\n",
    "        self.temp = temp\n",
    "        self.top_p = top_p\n",
    "        self.max_tokens = max_tokens\n",
    "        self.seed = 42\n",
    "    def prompt(self, text):\n",
    "        prompt = {'model': self.model,\n",
    "                  'random_seed': self.seed,\n",
    "              'temperature': self.temp,\n",
    "              'top_p': self.top_p,\n",
    "              'max_tokens': self.max_tokens,\n",
    "              'messages': [{'role':'user', 'content': text}]\n",
    "             }\n",
    "        return prompt\n",
    "    \n",
    "    def structured_prompt(self, instruction, text):\n",
    "        prompt = {'model': self.model,\n",
    "                  'random_seed': self.seed,\n",
    "              'temperature': self.temp,\n",
    "              'top_p': self.top_p,\n",
    "              'max_tokens': self.max_tokens,\n",
    "              'messages': [{'role':'system', 'content': instruction},\n",
    "                          {'role':'user', 'content': text}]\n",
    "             }\n",
    "        return prompt\n",
    "\n",
    "mistral = MistralModel(model, max_tokens = 512)\n",
    "\n",
    "instruction = \"ответь на вопрос\"\n",
    "text = \"тебя создали французы?\"\n",
    "response = requests.post(url, headers=headers, json=mistral.prompt(text))\n",
    "print(f'Вопрос: {text}')\n",
    "print(f\"Ответ: {response.json()['choices'][0]['message']['content']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc58e599",
   "metadata": {},
   "source": [
    "### Подготовка данных ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7e0f7f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, zipfile, io\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/rossyaykin/RuOpinionNE/refs/heads/main/src/src.zip'\n",
    "r = requests.get(url)\n",
    "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "z.extractall('')\n",
    "\n",
    "from src.utils import load_jsonl, save_jsonl, str2list, dict2tuple, extract_tuple, df2structure, form_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c7a21e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2556 1316\n"
     ]
    }
   ],
   "source": [
    "train_path = \"full.jsonl\"\n",
    "test_path = \"validation.jsonl\"\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/rossyaykin/RuOpinionNE/refs/heads/main/data/full.jsonl'\n",
    "train = load_jsonl(url, train_path)\n",
    "url = 'https://raw.githubusercontent.com/rossyaykin/RuOpinionNE/refs/heads/main/data/validation.jsonl'\n",
    "test = load_jsonl(url, test_path)\n",
    "\n",
    "print(len(train), len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea88f29",
   "metadata": {},
   "source": [
    "### Определения ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5d7422b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Runner():\n",
    "    def __init__(self, model, url, headers, train, test, n_shots = 5, sleeptime = 2):\n",
    "        self.model = model\n",
    "        self.url = url\n",
    "        self.headers = headers\n",
    "        self.train = train\n",
    "        self.test = test\n",
    "        self.n_shots = n_shots\n",
    "        self.sleeptime = sleeptime\n",
    "    \n",
    "    def run(self):\n",
    "        results = list()\n",
    "        for entry in tqdm(self.test):\n",
    "            time.sleep(self.sleeptime)\n",
    "            examples = [dict2tuple(x) for x in choices(self.train, k = n_shots)]\n",
    "            prompt = form_prompt(examples, entry['text'])\n",
    "            response = requests.post(self.url,\n",
    "                                     headers=self.headers,\n",
    "                                     json=self.model.prompt(prompt))\n",
    "            result = []\n",
    "            if response.status_code == 200:\n",
    "                response = response.json()['choices'][0]['message']['content']\n",
    "                try:\n",
    "                    result = ast.literal_eval(response)\n",
    "                except (SyntaxError, ValueError):\n",
    "                    print(f'bad response, iteration:{len(results)}')\n",
    "            else:\n",
    "                print(f'bad response, iteration:{len(results)}') \n",
    "            results.append((entry['sent_id'],\n",
    "                            entry['text'],\n",
    "                            dict2tuple(entry)[1], # gold opinions\n",
    "                            result)) # pred opinions\n",
    "        return results\n",
    "\n",
    "def get_path(temp, n_shots):\n",
    "    path = f'./results/Mistral/Mistral_bl_{n_shots}shot_{temp}temp'\n",
    "    # returns full path but without \".csv\"\n",
    "    return path\n",
    "\n",
    "def save(dataframe, path, raw = True):\n",
    "    outdir, outname = '/'.join(path.split('/')[:-1]), path.split('/')[-1]\n",
    "    if not os.path.exists(outdir):\n",
    "        os.mkdir(outdir)\n",
    "    if raw:\n",
    "        dataframe.to_csv(f'{path}_raw.csv', index = False)\n",
    "    else:\n",
    "        dataframe.to_csv(f'{path}.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0588cb",
   "metadata": {},
   "source": [
    "### Тест на одном примере ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a7737b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Промпт--:\n",
      "\n",
      "Ты эксперт в оценке тональности.\n",
      "Тебе нужно найти все негативные и позитивные отношения между сущностями в тексте и вывести их в следующем формате:\n",
      "[источник отношения, объект отношения, выражение в тексте содержащее оценку, оценка (POS/NEG)]\n",
      "Если источником отношения является автор, то пиши:\n",
      "['AUTHOR', объект отношения, выражение в тексте содержащее оценку, оценка (POS/NEG)]\n",
      "Если выраженного источника нет, то пиши:\n",
      "['NULL', объект отношения, выражение в тексте содержащее оценку, оценка (POS/NEG)]\n",
      "Допустимо вернуть пустой ответ:\n",
      "[]\n",
      "Не нужно давать пояснений к ответу.\n",
      "Примеры\n",
      "Текст: Президент Башкирии Муртаза Рахимов в очередной раз решил поменять главу своей администрации.\n",
      "Ответ: [['Муртаза Рахимов', 'главу своей администрации', 'поменять', 'NEG']]\n",
      "Текст: Вчера он уволил Азамата Сагитова, который возглавил башкирскую администрацию год назад после вынужденной отставки Радия Хабирова, сейчас занимающего пост заместителя начальника управления президента РФ по внутренней политике.\n",
      "Ответ: [['NULL', 'Азамата Сагитова', 'уволил', 'NEG']]\n",
      "Текст: Преемник господина Сагитова, которого перевели на работу в мэрию Уфы, пока не назначен.\n",
      "Ответ: []\n",
      "Текст: Как сообщил \"Ъ\" глава пресс-службы башкирского президента Айрат Мурзагалиев, вчера Муртаза Рахимов подписал указ об отставке главы своей администрации.\n",
      "Ответ: [['Муртаза Рахимов', 'главы своей администрации', 'отставке', 'NEG']]\n",
      "Текст: 42-летний Азамат Сагитов, ранее работавший в местных структурах по поддержке малого бизнеса, а затем главой одной из районных администраций Уфы, занял этот пост в июле прошлого года.\n",
      "Ответ: []\n",
      "Текст: Этому назначению предшествовал громкий скандал, сопровождавший историю отставки прежнего главы администрации Радия Хабирова.\n",
      "Ответ: \n"
     ]
    }
   ],
   "source": [
    "n_shots = 5\n",
    "examples = [dict2tuple(x) for x in train[:n_shots]]\n",
    "text, target = dict2tuple(train[n_shots])\n",
    "\n",
    "sample_prompt = form_prompt(examples, text)\n",
    "print(f'--Промпт--:\\n\\n{sample_prompt}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b38f6796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Текст--:\n",
      "Этому назначению предшествовал громкий скандал, сопровождавший историю отставки прежнего главы администрации Радия Хабирова.\n",
      "--Таргет--:\n",
      "[['NULL', 'Радия Хабирова', 'громкий скандал', 'NEG']]\n",
      "--Предикт--:\n",
      "[['NULL', 'Радия Хабирова', 'скандал', 'NEG'], ['NULL', 'Радия Хабирова', 'отставки', 'NEG']]\n"
     ]
    }
   ],
   "source": [
    "response = requests.post(url, headers=headers, json=mistral.prompt(sample_prompt))\n",
    "response = response.json()['choices'][0]['message']['content']\n",
    "result = ast.literal_eval(response)\n",
    "\n",
    "print(f'--Текст--:\\n{text}')\n",
    "print(f'--Таргет--:\\n{target}')\n",
    "print(f'--Предикт--:\\n{extract_tuple(result)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01598c65",
   "metadata": {},
   "source": [
    "### Инференс ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b78b8243",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 1181/1316 [1:20:47<10:01,  4.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bad response, iteration:1180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1316/1316 [1:30:08<00:00,  4.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 6min 21s\n",
      "Wall time: 1h 30min 8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "params = {'temp': 0.4,\n",
    "          'seed': SEED,\n",
    "          'top_p': 0.9,\n",
    "          'max_tokens': 512}\n",
    "mistral = MistralModel(model, **params)\n",
    "n_shots = 15\n",
    "runner = Runner(mistral, url, headers, train, val, n_shots)\n",
    "\n",
    "path = get_path(mistral.temp, n_shots)\n",
    "result = runner.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2eadf6a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./results/Mistral/Mistral_bl_15shot_0.4temp\n",
      "(7, 'Напомним, на казахстанском пограничном временном посту \"Арканкерген\" были обнаружены обгоревшие тела 14 пограничников и 1 егеря.', [], [])\n"
     ]
    }
   ],
   "source": [
    "print(path)\n",
    "print(result[7])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad6c329",
   "metadata": {},
   "source": [
    "### Результаты ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "279ef007",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_id</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>В числе участников президентской борьбы есть о...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Кандидатке на пост президента 54 года, она род...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Сама женщина заявила, что встречаться с сыном ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[NULL, женщина, встречаться с сыном ей пришло...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Они снимали нас все эти 5 минут, что длилось с...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[NULL, Влад, ничего лишнего, NEG]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Кроме того, по словам женщины на щеке сына Све...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[NULL, сына, синяк, NEG]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sent_id                                               text target  \\\n",
       "0        0  В числе участников президентской борьбы есть о...     []   \n",
       "1        1  Кандидатке на пост президента 54 года, она род...     []   \n",
       "2        2  Сама женщина заявила, что встречаться с сыном ...     []   \n",
       "3        3  Они снимали нас все эти 5 минут, что длилось с...     []   \n",
       "4        4  Кроме того, по словам женщины на щеке сына Све...     []   \n",
       "\n",
       "                                                pred  \n",
       "0                                                 []  \n",
       "1                                                 []  \n",
       "2  [[NULL, женщина, встречаться с сыном ей пришло...  \n",
       "3                [[NULL, Влад, ничего лишнего, NEG]]  \n",
       "4                         [[NULL, сына, синяк, NEG]]  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = pd.DataFrame(result, columns = ['sent_id', 'text', 'target', 'pred'])\n",
    "output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f87db0f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./results/Mistral/Mistral_bl_15shot_0.4temp\n"
     ]
    }
   ],
   "source": [
    "print(path)\n",
    "save(output, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e60e6dc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_id</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>В числе участников президентской борьбы есть о...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Кандидатке на пост президента 54 года, она род...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Сама женщина заявила, что встречаться с сыном ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[NULL, женщина, встречаться с сыном ей пришло...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Они снимали нас все эти 5 минут, что длилось с...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[NULL, Влад, ничего лишнего, NEG]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Кроме того, по словам женщины на щеке сына Све...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[NULL, сына, синяк, NEG]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sent_id                                               text target  \\\n",
       "0        0  В числе участников президентской борьбы есть о...     []   \n",
       "1        1  Кандидатке на пост президента 54 года, она род...     []   \n",
       "2        2  Сама женщина заявила, что встречаться с сыном ...     []   \n",
       "3        3  Они снимали нас все эти 5 минут, что длилось с...     []   \n",
       "4        4  Кроме того, по словам женщины на щеке сына Све...     []   \n",
       "\n",
       "                                                pred  \n",
       "0                                                 []  \n",
       "1                                                 []  \n",
       "2  [[NULL, женщина, встречаться с сыном ей пришло...  \n",
       "3                [[NULL, Влад, ничего лишнего, NEG]]  \n",
       "4                         [[NULL, сына, синяк, NEG]]  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = pd.DataFrame([(x[0], x[1], x[2], str2list(extract_tuple(x[3]))) for x in result],\n",
    "                      columns = ['sent_id', 'text', 'target', 'pred'])\n",
    "output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1be5bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "save(output, path, raw = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd1bc6d",
   "metadata": {},
   "source": [
    "### csv to jsonl ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15b0595e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sent_id': 3,\n",
       " 'text': 'Они снимали нас все эти 5 минут, что длилось свидание, чтобы Влад ничего лишнего мне не сказал.',\n",
       " 'opinions': [{'Source': [['NULL'], ['0:0']],\n",
       "   'Target': [['Влад'], ['61:65']],\n",
       "   'Polar_expression': [['ничего лишнего'], ['66:80']],\n",
       "   'Polarity': 'NEG'}]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final = df2structure(output)\n",
    "final[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4921c2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_jsonl(final, path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
